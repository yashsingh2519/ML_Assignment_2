{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANS 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier:\n",
      "Accuracy: 0.956140350877193\n",
      "Precision: 0.9583333333333334\n",
      "Recall: 0.971830985915493\n",
      "\n",
      "AdaBoostClassifier:\n",
      "Accuracy: 0.9649122807017544\n",
      "Precision: 0.958904109589041\n",
      "Recall: 0.9859154929577465\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = load_breast_cancer()\n",
    "X, y = df.data, df.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bag = bagging.predict(X_test)\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_ada = ada.predict(X_test)\n",
    "\n",
    "print(\"BaggingClassifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_bag))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_bag))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_bag))\n",
    "\n",
    "print(\"\\nAdaBoostClassifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ada))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_ada))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANS 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[184   2]\n",
      " [  0  14]]\n",
      "Precision: 0.875\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, \n",
    "                           n_redundant=10, n_clusters_per_class=1,\n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANS 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'evals_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m evals \u001b[38;5;241m=\u001b[39m [(dtrain, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m), (dval, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mtrain(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39mevals, verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevals_result\u001b[49m()\n\u001b[0;32m     24\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     25\u001b[0m x_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(epochs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'evals_result'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, \n",
    "                           n_redundant=5, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "evals = [(dtrain, 'train'), (dval, 'validation')]\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round=200, early_stopping_rounds=10, evals=evals, verbose_eval=False)\n",
    "\n",
    "results = model.evals_result()\n",
    "\n",
    "epochs = len(results['train']['logloss'])\n",
    "x_axis = range(epochs)\n",
    "\n",
    "plt.plot(x_axis, results['train']['logloss'], label='Train')\n",
    "plt.plot(x_axis, results['validation']['logloss'], label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('XGBoost Log Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANS 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(model, \"rf_model.joblib\")\n",
    "\n",
    "loaded_model = joblib.load(\"rf_model.joblib\")\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANS 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7622377622377622\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "\n",
    "df = df[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"Survived\"]]\n",
    "df = df.dropna()\n",
    "\n",
    "X = pd.get_dummies(df.drop(\"Survived\", axis=1), drop_first=True)\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
